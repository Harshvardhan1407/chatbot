{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scipy --quiet\n",
    "! pip install tenacity --quiet\n",
    "! pip install tiktoken --quiet\n",
    "! pip install termcolor --quiet\n",
    "! pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n",
    "\n",
    "GPT_MODEL = \"gpt-4o\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n",
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_n_day_weather_forecast\",\n",
    "            \"description\": \"Get an N-day weather forecast\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                    \"num_days\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The number of days to forecast\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Could you please specify the city and state for which you would like to know the weather?', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 3, 93, 81, 74, 54, 65, 51, 99, 35, 28, 16, 75, 48, 20, 17, 55, 43, 62]\n",
      "[100, 3, 93, 81, 74, 54, 65, 55, 99, 35, 28, 16, 75, 48, 20, 17, 51, 43, 62]\n",
      "[100, 3, 93, 81, 74, 75, 65, 55, 99, 35, 28, 16, 54, 48, 20, 17, 51, 43, 62]\n",
      "[100, 3, 93, 99, 74, 75, 65, 55, 81, 35, 28, 16, 54, 48, 20, 17, 51, 43, 62]\n",
      "[100, 99, 93, 3, 74, 75, 65, 55, 81, 35, 28, 16, 54, 48, 20, 17, 51, 43, 62]\n",
      "[100, 99, 93, 81, 74, 75, 65, 55, 3, 35, 28, 16, 54, 48, 20, 17, 51, 43, 62]\n",
      "[100, 99, 93, 81, 74, 75, 65, 55, 62, 35, 28, 16, 54, 48, 20, 17, 51, 43, 3]\n",
      "[99, 3, 93, 81, 74, 75, 65, 55, 62, 35, 28, 16, 54, 48, 20, 17, 51, 43, 100]\n",
      "[99, 81, 93, 3, 74, 75, 65, 55, 62, 35, 28, 16, 54, 48, 20, 17, 51, 43, 100]\n",
      "[99, 81, 93, 62, 74, 75, 65, 55, 3, 35, 28, 16, 54, 48, 20, 17, 51, 43, 100]\n",
      "[99, 81, 93, 62, 74, 75, 65, 55, 43, 35, 28, 16, 54, 48, 20, 17, 51, 3, 100]\n",
      "[93, 81, 3, 62, 74, 75, 65, 55, 43, 35, 28, 16, 54, 48, 20, 17, 51, 99, 100]\n",
      "[93, 81, 75, 62, 74, 3, 65, 55, 43, 35, 28, 16, 54, 48, 20, 17, 51, 99, 100]\n",
      "[93, 81, 75, 62, 74, 54, 65, 55, 43, 35, 28, 16, 3, 48, 20, 17, 51, 99, 100]\n",
      "[81, 51, 75, 62, 74, 54, 65, 55, 43, 35, 28, 16, 3, 48, 20, 17, 93, 99, 100]\n",
      "[81, 74, 75, 62, 51, 54, 65, 55, 43, 35, 28, 16, 3, 48, 20, 17, 93, 99, 100]\n",
      "[75, 74, 17, 62, 51, 54, 65, 55, 43, 35, 28, 16, 3, 48, 20, 81, 93, 99, 100]\n",
      "[75, 74, 65, 62, 51, 54, 17, 55, 43, 35, 28, 16, 3, 48, 20, 81, 93, 99, 100]\n",
      "[75, 74, 65, 62, 51, 54, 48, 55, 43, 35, 28, 16, 3, 17, 20, 81, 93, 99, 100]\n",
      "[74, 20, 65, 62, 51, 54, 48, 55, 43, 35, 28, 16, 3, 17, 75, 81, 93, 99, 100]\n",
      "[74, 62, 65, 20, 51, 54, 48, 55, 43, 35, 28, 16, 3, 17, 75, 81, 93, 99, 100]\n",
      "[74, 62, 65, 55, 51, 54, 48, 20, 43, 35, 28, 16, 3, 17, 75, 81, 93, 99, 100]\n",
      "[65, 62, 17, 55, 51, 54, 48, 20, 43, 35, 28, 16, 3, 74, 75, 81, 93, 99, 100]\n",
      "[65, 62, 54, 55, 51, 17, 48, 20, 43, 35, 28, 16, 3, 74, 75, 81, 93, 99, 100]\n",
      "[62, 3, 54, 55, 51, 17, 48, 20, 43, 35, 28, 16, 65, 74, 75, 81, 93, 99, 100]\n",
      "[62, 55, 54, 3, 51, 17, 48, 20, 43, 35, 28, 16, 65, 74, 75, 81, 93, 99, 100]\n",
      "[62, 55, 54, 43, 51, 17, 48, 20, 3, 35, 28, 16, 65, 74, 75, 81, 93, 99, 100]\n",
      "[55, 16, 54, 43, 51, 17, 48, 20, 3, 35, 28, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[55, 51, 54, 43, 16, 17, 48, 20, 3, 35, 28, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[55, 51, 54, 43, 35, 17, 48, 20, 3, 16, 28, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[54, 51, 28, 43, 35, 17, 48, 20, 3, 16, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[54, 51, 48, 43, 35, 17, 28, 20, 3, 16, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[51, 16, 48, 43, 35, 17, 28, 20, 3, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[51, 43, 48, 16, 35, 17, 28, 20, 3, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[51, 43, 48, 20, 35, 17, 28, 16, 3, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[48, 43, 3, 20, 35, 17, 28, 16, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[48, 43, 28, 20, 35, 17, 3, 16, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[43, 16, 28, 20, 35, 17, 3, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[43, 35, 28, 20, 16, 17, 3, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[35, 3, 28, 20, 16, 17, 43, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[35, 20, 28, 3, 16, 17, 43, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[28, 20, 17, 3, 16, 35, 43, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[20, 16, 17, 3, 28, 35, 43, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[17, 16, 3, 20, 28, 35, 43, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "[16, 3, 17, 20, 28, 35, 43, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n",
      "Heap Sort: [3, 16, 17, 20, 28, 35, 43, 48, 51, 54, 55, 62, 65, 74, 75, 81, 93, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "def heapify(arr, n, i):\n",
    "    largest = i\n",
    "    l = 2 * i + 1\n",
    "    r = 2 * i + 2\n",
    "\n",
    "    if l < n and arr[i] < arr[l]:\n",
    "        largest = l\n",
    "\n",
    "    if r < n and arr[largest] < arr[r]:\n",
    "        largest = r\n",
    "\n",
    "    if largest != i:\n",
    "        arr[i], arr[largest] = arr[largest], arr[i]\n",
    "        print(arr)\n",
    "        heapify(arr, n, largest)\n",
    "\n",
    "def heap_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n // 2 - 1, -1, -1):\n",
    "        heapify(arr, n, i)\n",
    "\n",
    "    for i in range(n-1, 0, -1):\n",
    "        arr[i], arr[0] = arr[0], arr[i]\n",
    "        heapify(arr, i, 0)\n",
    "    return arr\n",
    "\n",
    "l = [100, 3, 93, 81, 74, 54, 65, 51, 43, 35, 28, 16, 75, 48, 20, 17, 55, 99, 62]\n",
    "print(\"Heap Sort:\", heap_sort(l.copy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
